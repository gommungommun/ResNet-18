{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-17T03:59:24.248744Z",
     "start_time": "2025-02-17T03:59:24.241965Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2d = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        # 첫 번째 conv layer적용\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # 두 번째 conv layer적용\n",
    "        out = self.conv2d(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # downsampling이 필요할 경우\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # skip connection\n",
    "        out = out+identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T04:07:13.075354Z",
     "start_time": "2025-02-17T04:07:13.069375Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)"
   ],
   "id": "2ef6d774f1aa0a56",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T04:28:40.837186Z",
     "start_time": "2025-02-17T04:28:40.826682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        # ResNet18 archtecture에 따라 layer설계\n",
    "        self.layer1 = self._make_layer(64, 2)\n",
    "        self.layer2 = self._make_layer(128, 2)\n",
    "        self.layer3 = self._make_layer(256, 2)\n",
    "        self.layer4 = self._make_layer(512, 2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Linear(512, num_classes)\n",
    "\n",
    "        # weigth 초기화\n",
    "        self.apply(initialize_weights)\n",
    "\n",
    "    def _make_layer(self, out_channels, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.in_channels != out_channels:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1,stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        layers = [ResidualBlock(self.in_channels, out_channels, stride=stride, downsample=downsample)]\n",
    "        self.in_channels = out_channels\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(ResidualBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "\n",
    "        return x"
   ],
   "id": "3c1336db62bee4ac",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T04:34:02.523051Z",
     "start_time": "2025-02-17T04:34:02.483043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "train_transforms = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomResizedCrop(height=224, width=224, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n",
    "    A.Cutout(num_holes=8, max_h_size=16, max_w_size=32, p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "def apply_transforms(image):\n",
    "    # image should be a numpy array with shape (H, W, C)\n",
    "    return train_transforms(image=image)['image']"
   ],
   "id": "e6ee4572e6985681",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CVIP\\AppData\\Local\\Temp\\ipykernel_11176\\3024017011.py:6: UserWarning: 1 validation error for InitSchema\n",
      "size\n",
      "  Field required [type=missing, input_value={'scale': (0.8, 1.0), 'ra...rpolation': 0, 'p': 1.0}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "  A.RandomResizedCrop(height=224, width=224, scale=(0.8, 1.0), ratio=(0.75, 1.33)),\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "6 validation errors for InitSchema\np\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nscale\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nratio\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nsize\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\ninterpolation\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nmask_interpolation\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 6\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01malbumentations\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mA\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01malbumentations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpytorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ToTensorV2\n\u001B[0;32m      4\u001B[0m train_transforms \u001B[38;5;241m=\u001B[39m A\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m      5\u001B[0m     A\u001B[38;5;241m.\u001B[39mHorizontalFlip(p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m),\n\u001B[1;32m----> 6\u001B[0m     A\u001B[38;5;241m.\u001B[39mRandomResizedCrop(height\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m224\u001B[39m, width\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m224\u001B[39m, scale\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.8\u001B[39m, \u001B[38;5;241m1.0\u001B[39m), ratio\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.75\u001B[39m, \u001B[38;5;241m1.33\u001B[39m)),\n\u001B[0;32m      7\u001B[0m     A\u001B[38;5;241m.\u001B[39mCutout(num_holes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, max_h_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m, max_w_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m),\n\u001B[0;32m      8\u001B[0m     A\u001B[38;5;241m.\u001B[39mNormalize(mean\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.485\u001B[39m, \u001B[38;5;241m0.456\u001B[39m, \u001B[38;5;241m0.406\u001B[39m), std\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.229\u001B[39m, \u001B[38;5;241m0.224\u001B[39m, \u001B[38;5;241m0.225\u001B[39m)),\n\u001B[0;32m      9\u001B[0m     ToTensorV2()\n\u001B[0;32m     10\u001B[0m ])\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_transforms\u001B[39m(image):\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;66;03m# image should be a numpy array with shape (H, W, C)\u001B[39;00m\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m train_transforms(image\u001B[38;5;241m=\u001B[39mimage)[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimage\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\albumentations\\core\\validation.py:48\u001B[0m, in \u001B[0;36mValidatedTransformMeta.__new__.<locals>.custom_init\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     46\u001B[0m warn(\u001B[38;5;28mstr\u001B[39m(e), stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# Use default values for invalid parameters\u001B[39;00m\n\u001B[1;32m---> 48\u001B[0m config \u001B[38;5;241m=\u001B[39m dct[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInitSchema\u001B[39m\u001B[38;5;124m\"\u001B[39m]()\n\u001B[0;32m     49\u001B[0m validated_kwargs \u001B[38;5;241m=\u001B[39m config\u001B[38;5;241m.\u001B[39mmodel_dump()\n\u001B[0;32m     50\u001B[0m validated_kwargs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)  \u001B[38;5;66;03m# Also remove from default values\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:214\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[1;34m(self, **data)\u001B[0m\n\u001B[0;32m    212\u001B[0m \u001B[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001B[39;00m\n\u001B[0;32m    213\u001B[0m __tracebackhide__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m--> 214\u001B[0m validated_self \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__pydantic_validator__\u001B[38;5;241m.\u001B[39mvalidate_python(data, self_instance\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m validated_self:\n\u001B[0;32m    216\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    217\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mA custom validator is returning a value other than `self`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReturning anything other than `self` from a top level model validator isn\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt supported when validating via `__init__`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m    220\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m,\n\u001B[0;32m    221\u001B[0m     )\n",
      "\u001B[1;31mValidationError\u001B[0m: 6 validation errors for InitSchema\np\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nscale\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nratio\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nsize\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\ninterpolation\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing\nmask_interpolation\n  Field required [type=missing, input_value={}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/missing"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c239a124b42454b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
